{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Introduction to Artificial Neural Networks with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:11:01.105727Z",
     "start_time": "2020-06-01T13:10:57.266771Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import reciprocal\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:11:01.122716Z",
     "start_time": "2020-06-01T13:11:01.107903Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ingestion\n",
    "###########\n",
    "(train_data, y_train), (test_data, y_test) = boston_housing.load_data()\n",
    "\n",
    "# Preprocessing\n",
    "###############\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(train_data)\n",
    "x_test = sc.transform(test_data)\n",
    "\n",
    "x_train__train, x_train__val, y_train__train, y_train__val = train_test_split(x_train, y_train, test_size=0.15,\n",
    "                                                                             random_state=0)\n",
    "NUM_FEATURES = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning Neural Network Hyperparameters\n",
    "\n",
    "Some of the things to consider when using neural networks are:\n",
    "1. Architecture\n",
    "2. For an MLP, the no. of layers, size of layers / no. of neurons, type of activation function, weight inisialisation logic etc.\n",
    "\n",
    "How do you know what combinations of hyperparameters is the best fo the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way is to simply try many combinations of hyperparameters and see which ones work the best during k-fold CV. For this, we can wrap the model around a parameter search algorithm like `GridSearchCV` or `RandomizedSearchCV`.\n",
    "\n",
    "Using a function call, let's build a way to initialise models with keyword arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:11:01.135399Z",
     "start_time": "2020-06-01T13:11:01.128022Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(n_hidden_layers=1, n_neurons=64, learning_rate=3e-3, input_shape=(13,),\n",
    "                dropout=0.0, kernel_regularizer=None):\n",
    "    m = keras.models.Sequential()\n",
    "    \n",
    "    for l in range(n_hidden_layers):\n",
    "        m.add(keras.layers.Dense(n_neurons, activation='relu', input_shape=input_shape, \n",
    "                              kernel_regularizer=kernel_regularizer))\n",
    "        if 0.0 < dropout:\n",
    "            m.add(keras.layers.Dropout(0.5))\n",
    "    m.add(keras.layers.Dense(1))\n",
    "\n",
    "    optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    m.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T09:12:31.083499Z",
     "start_time": "2020-06-01T09:12:31.067422Z"
    }
   },
   "source": [
    "Here we execute a simple workflow on the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:11:04.374500Z",
     "start_time": "2020-06-01T13:11:01.138384Z"
    }
   },
   "outputs": [],
   "source": [
    "# BASELINE MODEL \n",
    "model0 = build_model()\n",
    "history0 = model0.fit(x_train__train, y_train__train, \n",
    "                      epochs=20, batch_size=32, \n",
    "                      validation_data=(x_train__val, y_train__val), verbose=0) # Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:11:04.932549Z",
     "start_time": "2020-06-01T13:11:04.380868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.033567],\n",
       "       [17.042376],\n",
       "       [20.761349],\n",
       "       [33.363026],\n",
       "       [26.3914  ],\n",
       "       [15.98591 ],\n",
       "       [25.909231],\n",
       "       [23.377611],\n",
       "       [21.331947],\n",
       "       [18.341013]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.predict(x_test[:10]) # Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now build a `keras_reg` that wraps the Keras model, and now can be treated like a classifier like one in `sklearn`. This allows us to implement sklearn functions like `RandomizedSearch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:11:04.948162Z",
     "start_time": "2020-06-01T13:11:04.937586Z"
    }
   },
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_fn=build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:11:07.589688Z",
     "start_time": "2020-06-01T13:11:04.954337Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.701542, 18.000772, 20.44781 , 34.402363, 26.31796 , 16.30954 ,\n",
       "       25.831837, 22.999666, 21.384874, 17.611002], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training baseline model using keras_clf (treating it like a model from sklearn)\n",
    "stop_early_checkpoint = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "keras_reg.fit(x_train__train, y_train__train, \n",
    "              epochs=20, batch_size=32, callbacks=[stop_early_checkpoint],\n",
    "              validation_data=(x_train__val, y_train__val), verbose=0) # Train\n",
    "keras_reg.predict(x_test[:10]) # Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:11:12.136639Z",
     "start_time": "2020-06-01T13:11:07.593941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11.008568, 17.386282, 21.598707, 33.99249 , 26.74907 , 15.577572,\n",
       "       27.03369 , 23.962278, 20.918337, 16.829638], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = keras.regularizers.l2(l=0.01)\n",
    "# Training model with regularisation\n",
    "stop_early_checkpoint = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "keras_reg2 = keras.wrappers.scikit_learn.KerasRegressor(build_fn=build_model, \n",
    "                                                         kernel_regularizer=r)\n",
    "keras_reg2.fit(x_train__train, y_train__train, \n",
    "              epochs=20, batch_size=32, callbacks=[stop_early_checkpoint],\n",
    "              validation_data=(x_train__val, y_train__val), verbose=0) # Train\n",
    "keras_reg2.predict(x_test[:10]) # Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:17:14.395858Z",
     "start_time": "2020-06-01T13:14:04.073225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 34ms/step - loss: 83.2002 - mae: 7.0578\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 46.4505 - mae: 4.7354\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 24.1672 - mae: 3.9641\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 101.8218 - mae: 7.1508\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 578.5460 - mae: 22.2267\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 551.2391 - mae: 21.6431\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 552.5931 - mae: 21.9984\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 672.3865 - mae: 24.0176\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 575.6990 - mae: 22.1455\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 557.0381 - mae: 21.7490\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 542.7797 - mae: 21.7947\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 659.4439 - mae: 23.8134\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 572.1570 - mae: 22.1385\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 529.1765 - mae: 21.2187\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 538.1482 - mae: 21.5811\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 665.9861 - mae: 23.8912\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 527.9332 - mae: 21.0051\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 542.8915 - mae: 21.4863\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 513.0142 - mae: 21.1189\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 629.0765 - mae: 23.1863\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 437.0973 - mae: 19.1292\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 506.0562 - mae: 20.3860\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 361.1697 - mae: 17.7251\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 467.5027 - mae: 19.8039\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 566.2075 - mae: 21.9735\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 555.4775 - mae: 21.7432\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 539.7740 - mae: 21.7114\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 652.3176 - mae: 23.6252\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 38.8777 - mae: 4.6240\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 47.8973 - mae: 5.3647\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 330.4764 - mae: 16.8934\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 88.8184 - mae: 7.5700\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 108.2462 - mae: 8.8558\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 145.9536 - mae: 10.0060\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 122.1153 - mae: 9.3662\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 200.2504 - mae: 11.9291\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 566.5164 - mae: 21.9908\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 508.6504 - mae: 20.6651\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 502.2291 - mae: 20.8463\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 653.9032 - mae: 23.6996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryanlim/.pyenv/versions/3.7.2/envs/botanic/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=4, error_score='raise-deprecating',\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x138fef208>,\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'dropout': (0.0, 0.1, 0.2, 0.3, 0.4,\n",
       "                                                    0.5),\n",
       "                                        'kernel_regularizer': (None,\n",
       "                                                               <tensorflow.python.keras.regularizers.L1L2 object at 0x13a644278>,\n",
       "                                                               <tensorflow.python.keras.regularizers.L1L2 object at 0x13a644630>),\n",
       "                                        'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x13a644048>,\n",
       "                                        'n_hidden_layers': (1, 2, 3, 4, 5),\n",
       "                                        'n_neurons': (6, 7, 8, 9, 10, 11)},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impementing RandomizedSearch on a Keras model.\n",
    "param_dist = {\n",
    "    'n_hidden_layers' : (1,2,3,4,5),\n",
    "    'n_neurons' : (6,7,8,9,10,11),\n",
    "    'learning_rate' : reciprocal(3e-4, 3e-2),\n",
    "    'kernel_regularizer' : (None, \n",
    "                     keras.regularizers.l2(l=0.01),\n",
    "                     keras.regularizers.l1(l=0.001),),\n",
    "    'dropout' : (0.0, 0.1, 0.2, 0.3, 0.4, 0.5),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_dist, n_iter=10, cv=4)\n",
    "rnd_search_cv.fit(x_train__train, y_train__train, \n",
    "              epochs=10, batch_size=512, callbacks=[stop_early_checkpoint],\n",
    "              validation_data=(x_train__val, y_train__val), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:17:14.403481Z",
     "start_time": "2020-06-01T13:17:14.398573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropout': 0.0, 'kernel_regularizer': <tensorflow.python.keras.regularizers.L1L2 object at 0x13a644278>, 'learning_rate': 0.02343330549173664, 'n_hidden_layers': 5, 'n_neurons': 6}\n"
     ]
    }
   ],
   "source": [
    "# Obtaining the best model params\n",
    "print(rnd_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:17:14.413433Z",
     "start_time": "2020-06-01T13:17:14.406972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-63.79938958615673\n"
     ]
    }
   ],
   "source": [
    "print(rnd_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from here, you can save the model, evalauate on test set and if happy, deploy it to production. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
