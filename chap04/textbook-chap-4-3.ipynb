{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Introduction to Artificial Neural Networks with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:41:26.486653Z",
     "start_time": "2020-06-01T13:41:23.847281Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import reciprocal\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:41:36.941621Z",
     "start_time": "2020-06-01T13:41:26.489323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 10000)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "##########\n",
    "# Ingestion\n",
    "##########\n",
    "VOCABULARY_SIZE = 10000\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=VOCABULARY_SIZE)\n",
    "\n",
    "##########\n",
    "# Preprocessing\n",
    "##########\n",
    "def vectorize_sequences(sequences, dimension=VOCABULARY_SIZE):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "          results[i, sequence] = 1.\n",
    "    return results\n",
    "x_train = vectorize_sequences(train_data)\n",
    "print(x_train.shape)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "print(y_train.shape)\n",
    "y_test = np.asarray(test_labels).astype('float32')\n",
    "\n",
    "# Train-Validation Split\n",
    "x_train__train, x_train__val, y_train__train, y_train__val = train_test_split(x_train, y_train, test_size=0.4,\n",
    "                                                                             random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning Neural Network Hyperparameters\n",
    "\n",
    "Some of the things to consider when using neural networks are:\n",
    "1. Architecture\n",
    "2. For an MLP, the no. of layers, size of layers / no. of neurons, type of activation function, weight inisialisation logic etc.\n",
    "\n",
    "How do you know what combinations of hyperparameters is the best fo the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way is to simply try many combinations of hyperparameters and see which ones work the best during k-fold CV. For this, we can wrap the model around a parameter search algorithm like `GridSearchCV` or `RandomizedSearchCV`.\n",
    "\n",
    "Using a function call, let's build a way to initialise models with keyword arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:41:36.956636Z",
     "start_time": "2020-06-01T13:41:36.944003Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(n_hidden_layers=1, n_neurons=30, learning_rate=3e-3, input_shape=(10000,),\n",
    "                dropout=0.0, kernel_regularizer=None):\n",
    "    m = keras.models.Sequential()\n",
    "    for l in range(n_hidden_layers):\n",
    "        m.add(keras.layers.Dense(n_neurons, activation='relu', input_shape=input_shape,\n",
    "                                kernel_regularizer=kernel_regularizer))\n",
    "        if 0.0 < dropout:\n",
    "            m.add(keras.layers.Dropout(0.5))\n",
    "    m.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    m.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T09:12:31.083499Z",
     "start_time": "2020-06-01T09:12:31.067422Z"
    }
   },
   "source": [
    "Here we execute a simple workflow on the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:42:02.627985Z",
     "start_time": "2020-06-01T13:41:36.959355Z"
    }
   },
   "outputs": [],
   "source": [
    "# BASELINE MODEL \n",
    "model0 = build_model()\n",
    "history0 = model0.fit(x_train__train, y_train__train, \n",
    "                      epochs=20, batch_size=512, \n",
    "                      validation_data=(x_train__val, y_train__val), verbose=0) # Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:42:02.859173Z",
     "start_time": "2020-06-01T13:42:02.632845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1]], dtype=int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model0.predict(x_test[:3])>0.5).astype('int32').reshape(-1,1) # Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now build a `keras_clf` that wraps the Keras model, and now can be treated like a classifier like one in `sklearn`. This allows us to implement sklearn functions like `RandomizedSearch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:42:02.871795Z",
     "start_time": "2020-06-01T13:42:02.863253Z"
    }
   },
   "outputs": [],
   "source": [
    "keras_clf = keras.wrappers.scikit_learn.KerasClassifier(build_fn=build_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:42:11.928205Z",
     "start_time": "2020-06-01T13:42:02.876642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/bryanlim/.pyenv/versions/3.7.2/envs/botanic/lib/python3.7/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "[[0]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# Training baseline model using keras_clf (treating it like a model from sklearn)\n",
    "stop_early_checkpoint = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "keras_clf.fit(x_train__train, y_train__train, \n",
    "              epochs=20, batch_size=512, callbacks=[stop_early_checkpoint],\n",
    "              validation_data=(x_train__val, y_train__val), verbose=0) # Train\n",
    "print((keras_clf.predict(x_test[:3])>0.5).astype('int32').reshape(-1,1)) # Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:42:23.234981Z",
     "start_time": "2020-06-01T13:42:11.938129Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "r = keras.regularizers.l2(l=0.01)\n",
    "# Training model with regularisation\n",
    "stop_early_checkpoint = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "keras_clf2 = keras.wrappers.scikit_learn.KerasClassifier(build_fn=build_model, \n",
    "                                                         kernel_regularizer=r)\n",
    "keras_clf2.fit(x_train__train, y_train__train, \n",
    "              epochs=20, batch_size=512, callbacks=[stop_early_checkpoint],\n",
    "              validation_data=(x_train__val, y_train__val), verbose=0) # Train\n",
    "print(np.argmax(keras_clf2.predict(x_test[:3]), axis=-1)) # Predict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:42:39.836387Z",
     "start_time": "2020-06-01T13:42:23.239526Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Training model with regularisation\n",
    "stop_early_checkpoint = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "keras_clf3 = keras.wrappers.scikit_learn.KerasClassifier(build_fn=build_model, \n",
    "                                                         learning_rate=3e-4)\n",
    "keras_clf3.fit(x_train__train, y_train__train, \n",
    "              epochs=20, batch_size=512, callbacks=[stop_early_checkpoint],\n",
    "              validation_data=(x_train__val, y_train__val), verbose=0) # Train\n",
    "print(np.argmax(keras_clf3.predict(x_test[:3]), axis=-1)) # Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:57:46.727762Z",
     "start_time": "2020-06-01T13:42:39.840361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 3ms/step - loss: 0.3310 - accuracy: 0.8822\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.4099 - accuracy: 0.8588\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.3452 - accuracy: 0.8730\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.8138\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8384\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.4752 - accuracy: 0.8304\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 1.2302 - accuracy: 0.4938\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.2303 - accuracy: 0.5026\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.2303 - accuracy: 0.4926\n",
      "157/157 [==============================] - 19s 124ms/step - loss: 2.2060 - accuracy: 0.7966\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.2280 - accuracy: 0.8158\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 2.1330 - accuracy: 0.8382\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 1.8635 - accuracy: 0.4938\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8529 - accuracy: 0.4974\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 1.8579 - accuracy: 0.4926\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.5010 - accuracy: 0.8702\n",
      "157/157 [==============================] - 3s 17ms/step - loss: 0.5119 - accuracy: 0.8438\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 0.5015 - accuracy: 0.8544\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.3072 - accuracy: 0.8762\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.2991 - accuracy: 0.8834\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.3211 - accuracy: 0.8748\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.0614 - accuracy: 0.4938\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 2.0776 - accuracy: 0.5026\n",
      "157/157 [==============================] - 1s 8ms/step - loss: 2.0658 - accuracy: 0.4926\n",
      "157/157 [==============================] - 1s 6ms/step - loss: 0.3042 - accuracy: 0.8762\n",
      "157/157 [==============================] - 2s 12ms/step - loss: 0.3114 - accuracy: 0.8826\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.2842 - accuracy: 0.8840\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3160 - accuracy: 0.8724\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.3447 - accuracy: 0.8650\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.3365 - accuracy: 0.8632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x14de91f28>,\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'dropout': (0.0, 0.1, 0.2, 0.3, 0.4,\n",
       "                                                    0.5),\n",
       "                                        'kernel_regularizer': (None,\n",
       "                                                               <tensorflow.python.keras.regularizers.L1L2 object at 0x143810668>,\n",
       "                                                               <tensorflow.python.ke...\n",
       "                                        'n_neurons': array([20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "       37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "       54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70,\n",
       "       71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87,\n",
       "       88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impementing RandomizedSearch on a Keras model.\n",
    "param_dist = {\n",
    "    'n_hidden_layers' : (1,3,5,7),\n",
    "    'n_neurons' : np.arange(20,100),\n",
    "    'learning_rate' : reciprocal(3e-4, 3e-2),\n",
    "    'kernel_regularizer' : (None, \n",
    "                            keras.regularizers.l2(l=0.01),\n",
    "                            keras.regularizers.l1(l=0.001),),\n",
    "    'dropout' : (0.0, 0.1, 0.2, 0.3, 0.4, 0.5),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_clf, param_dist, n_iter=10, cv=3)\n",
    "rnd_search_cv.fit(x_train__train, y_train__train, \n",
    "              epochs=10, batch_size=512, callbacks=[stop_early_checkpoint],\n",
    "              validation_data=(x_train__val, y_train__val), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:57:46.748789Z",
     "start_time": "2020-06-01T13:57:46.740459Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropout': 0.0, 'kernel_regularizer': None, 'learning_rate': 0.0005693098669592988, 'n_hidden_layers': 3, 'n_neurons': 65}\n"
     ]
    }
   ],
   "source": [
    "# Obtaining the best model params\n",
    "print(rnd_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T13:57:46.761910Z",
     "start_time": "2020-06-01T13:57:46.754554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8809333443641663\n"
     ]
    }
   ],
   "source": [
    "print(rnd_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from here, you can save the model, evalauate on test set and if happy, deploy it to production. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
