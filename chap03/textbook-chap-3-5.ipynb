{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Introduction to Artificial Neural Networks with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Complex Models using the Functional API\n",
    "\n",
    "An example of a non-sequential neural network is the <b>Wide & Deep</b> neural network. This architecture connects all or part of the inputs directly to the output layer. With this architecture, it is possible to learn both deep patterns  (using the deep path) and simple rules (using the short path). \n",
    "\n",
    "In contrast, a regular network forces all the data to flow through all layers, and simple patterns might end up being distorted.\n",
    "\n",
    "<img src=\"img3.png\" width=\"900\"/>\n",
    "(Ref. 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:28.728197Z",
     "start_time": "2020-06-01T04:34:25.227365Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "from tensorflow import keras as tf_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:28.749461Z",
     "start_time": "2020-06-01T04:34:28.731142Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ingestion\n",
    "###########\n",
    "(train_data, y_train), (test_data, y_test) = boston_housing.load_data()\n",
    "\n",
    "# Preprocessing\n",
    "###############\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(train_data)\n",
    "x_test = sc.transform(test_data)\n",
    "\n",
    "x_train__train, x_train__val, y_train__train, y_train__val = train_test_split(x_train, y_train, test_size=0.15,\n",
    "                                                                             random_state=0)\n",
    "NUM_FEATURES = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Single input, Single output</b>\n",
    "\n",
    "Let's build a wide & deep network to tackle the **housing prices** problem. Take note of the comments describing each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:28.830889Z",
     "start_time": "2020-06-01T04:34:28.753361Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate Model\n",
    "###################\n",
    "\n",
    "# Input object. This is needed as we might have multiple inputs.\n",
    "input_layer = tf_keras.layers.Input(shape=NUM_FEATURES)\n",
    "\n",
    "# Dense layer with 30 neurons & RELU activation. Notice it is called like a function,\n",
    "# passing in the input layer. \n",
    "hidden_layer1 = tf_keras.layers.Dense(30, activation='relu')(input_layer)\n",
    "# Another Dense layer. Now, the first hidden layer is passed in.\n",
    "hidden_layer2 = tf_keras.layers.Dense(30, activation='relu')(hidden_layer1)\n",
    "\n",
    "# Concatenate layer. concatenates the input & the output of the 2nd hidden layer\n",
    "concat_layer = tf_keras.layers.Concatenate()([input_layer, hidden_layer2])\n",
    "\n",
    "# Output layer. Single neuron and no activation function.\n",
    "output_layer = tf_keras.layers.Dense(1)(concat_layer)\n",
    "\n",
    "# Finally, create the Keras model with this architecture.\n",
    "model0 = tf_keras.models.Model(inputs=[input_layer], outputs=output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above model is visually represented by the following network diagram:\n",
    "<img src=\"img3a.png\" width=\"150\"/>\n",
    "(Ref. 2)\n",
    "\n",
    "Once you have built the Keras model, the rest of the steps follows the simple workflow: Compile the model, train & tune it, and finalise the tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:29.431274Z",
     "start_time": "2020-06-01T04:34:28.834139Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train & Tune Model\n",
    "####################\n",
    "model0.compile(optimizer='sgd', loss='mean_squared_error', metrics=['mae'])\n",
    "history0 = model0.fit(x_train, y_train,  epochs = 10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:29.436017Z",
     "start_time": "2020-06-01T04:34:29.433288Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "# model0.save('model0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Multiple inputs, Single output</b>\n",
    "\n",
    "For this model, say we want to use a subset of the features for one input and another subset of features for another. To do this, we need to make changes on <u>both the architecture</u> and the <u>input data</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:29.480258Z",
     "start_time": "2020-06-01T04:34:29.438931Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate Model\n",
    "###################\n",
    "\n",
    "# Here, we need to specify the no. of features for each input layer\n",
    "input_layera = tf_keras.layers.Input(shape=(10,))\n",
    "input_layerb = tf_keras.layers.Input(shape=(7,))\n",
    "\n",
    "# Dense layers, Concatenate layer & Output layer is the same as previous complex workflows\n",
    "hidden_layer1 = tf_keras.layers.Dense(30, activation='relu')(input_layerb)\n",
    "hidden_layer2 = tf_keras.layers.Dense(30, activation='relu')(hidden_layer1)\n",
    "concat_layer = tf_keras.layers.Concatenate()([input_layera, hidden_layer2])\n",
    "output_layer = tf_keras.layers.Dense(1)(concat_layer)\n",
    "model1 = tf_keras.models.Model(inputs=[input_layera, input_layerb], outputs=output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we need to specify the features that will be fed into the different input layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:29.488061Z",
     "start_time": "2020-06-01T04:34:29.482282Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare data for training model\n",
    "#################################\n",
    "inputa_cols = list(range(0,10))\n",
    "inputb_cols = [1,5,6,7,8,11,12]\n",
    "x_train__trainA = x_train__train[:,inputa_cols]\n",
    "x_train__trainB = x_train__train[:,inputb_cols]\n",
    "x_train__val_A = x_train__val[:,inputa_cols]\n",
    "x_train__val_B = x_train__val[:,inputb_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:29.495961Z",
     "start_time": "2020-06-01T04:34:29.492502Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "# model1.save('model1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the model looks like:\n",
    "\n",
    "<img src=\"img3b.png\" width=\"150\"/>\n",
    "\n",
    "When we train the model, now we need to specify <u>a pair of matrices</u>. The same is true when performing validation & testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:30.849160Z",
     "start_time": "2020-06-01T04:34:29.499810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1339b5908>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train & Tune Model\n",
    "####################\n",
    "model1.compile(optimizer='sgd', loss='mean_squared_error', metrics=['mae'])\n",
    "model1.fit((x_train__trainA, x_train__trainB), y_train__train, epochs=20,\n",
    "           validation_data=((x_train__val_A, x_train__val_B), y_train__val), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:31.028278Z",
     "start_time": "2020-06-01T04:34:30.851689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 21.4732 - mae: 2.8256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7.2005463],\n",
       "       [19.398804 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare test data\n",
    "###################\n",
    "x_testA = x_test[:,inputa_cols]\n",
    "x_testB = x_test[:,inputb_cols]\n",
    "\n",
    "# Evaluation\n",
    "model1.evaluate((x_testA, x_testB), y_test)\n",
    "\n",
    "# Prediction\n",
    "model1.predict((x_testA[:2], x_testB[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Multiple inputs, Multiple outputs</b>\n",
    "\n",
    "For multiple outputs, you can use the following code snippets to help you.\n",
    "\n",
    "```python\n",
    "input_layera = tf_keras.layers.Input(shape=(10,))\n",
    "input_layerb = tf_keras.layers.Input(shape=(7,))\n",
    "\n",
    "hidden_layer1 = tf_keras.layers.Dense(30, activation='relu')(input_layerb)\n",
    "hidden_layer2 = tf_keras.layers.Dense(30, activation='relu')(hidden_layer1)\n",
    "concat_layer = tf_keras.layers.Concatenate()([input_layera, hidden_layer2])\n",
    "output_layer1 = tf_keras.layers.Dense(1)(concat_layer)\n",
    "output_layer2 = tf_keras.layers.Dense(1)(hidden_layer2) # Add this\n",
    "model3 = tf_keras.models.Model(inputs=[input_layera, input_layerb], \n",
    "                               outputs=[output_layer1, output_layer2]) # Change this\n",
    "```\n",
    "\n",
    "When compiling the model, use different metrics for different outputs\n",
    "\n",
    "```python\n",
    "model3.compile(optimizer='sgd', loss='mean_squared_error', metrics=['mae', 'mse'])\n",
    "```\n",
    "\n",
    "When evaluating the model, Keras returns the total loss, as well as the individual losses\n",
    "```python\n",
    "model3.evaluate((x_testA, x_testB), y_test)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Dynamic Models Using the Subclassing API\n",
    "\n",
    "To add flexibility, we can use the Subclassing API to subclass the Model and create the layers needed.\n",
    "\n",
    "Here, we separate the creating of the layers from their usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:31.038033Z",
     "start_time": "2020-06-01T04:34:31.030801Z"
    }
   },
   "outputs": [],
   "source": [
    "class WideAndDeepModel(tf_keras.models.Model):\n",
    "    def __init__(self, units=30, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden_layer1 = tf_keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden_layer2 = tf_keras.layers.Dense(units, activation=activation)\n",
    "        self.output_layer = tf_keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        inputa, inputb = inputs\n",
    "        hidden1 = self.hidden_layer1(inputb)\n",
    "        hidden2 = self.hidden_layer2(hidden1)\n",
    "        conct = tf_keras.layers.Concatenate()([inputa, hidden2])\n",
    "        ouptt = self.output_layer(conct)\n",
    "        return ouptt\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:32.456367Z",
     "start_time": "2020-06-01T04:34:31.040944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x133fb0fd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load & Train model\n",
    "model3 = WideAndDeepModel(30, 'relu')\n",
    "model3.compile(optimizer='sgd', loss='mean_squared_error', metrics=['mae'])\n",
    "model3.fit((x_train__trainA, x_train__trainB), y_train__train, epochs=20,\n",
    "           validation_data=((x_train__val_A, x_train__val_B), y_train__val), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:32.572023Z",
     "start_time": "2020-06-01T04:34:32.459904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 25.1871 - mae: 3.3219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7.9615493],\n",
       "       [16.662956 ]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate & Predict\n",
    "model3.evaluate((x_testA, x_testB), y_test)\n",
    "model3.predict((x_testA[:2], x_testB[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving & Restoring a Model\n",
    "\n",
    "This is useful when models take a long time to train or when you need access to a previously trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:32.594420Z",
     "start_time": "2020-06-01T04:34:32.574316Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving a model\n",
    "model1.save('model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:32.719754Z",
     "start_time": "2020-06-01T04:34:32.596313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16.56538 ],\n",
       "       [19.089624],\n",
       "       [17.795437],\n",
       "       [42.52627 ],\n",
       "       [20.118984]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load & Predict\n",
    "model1ld = tf_keras.models.load_model('model3.h5')\n",
    "model1ld.predict((x_testA[10:15], x_testB[10:15]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:17:00.759288Z",
     "start_time": "2020-06-01T04:17:00.754188Z"
    }
   },
   "source": [
    "Callbacks are useful to perform actions during training. For example, say we want to save the best model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:33.591641Z",
     "start_time": "2020-06-01T04:34:32.721914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1340d3fd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer = tf_keras.layers.Input(shape=NUM_FEATURES)\n",
    "hidden_layer1 = tf_keras.layers.Dense(30, activation='relu')(input_layer)\n",
    "hidden_layer2 = tf_keras.layers.Dense(30, activation='relu')(hidden_layer1)\n",
    "concat_layer = tf_keras.layers.Concatenate()([input_layer, hidden_layer2])\n",
    "output_layer = tf_keras.layers.Dense(1)(concat_layer)\n",
    "model0a = tf_keras.models.Model(inputs=[input_layer], outputs=output_layer)\n",
    "model0a.compile(optimizer='sgd', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Adding a callback to save only the best model\n",
    "save_best_checkpoint = tf_keras.callbacks.ModelCheckpoint('model0a_best.h5', save_best_only=True)\n",
    "model0a.fit(x_train, y_train,  epochs = 10, validation_data=(x_train__val, y_train__val), \n",
    "            callbacks=[save_best_checkpoint], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:34.178491Z",
     "start_time": "2020-06-01T04:34:33.593980Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x134334dd8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding a callback to Early Stop to avoid wasting time and resources\n",
    "# with no further optimisation\n",
    "stop_early_checkpoint = tf_keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "# Combine both callbacks. Use large epoch number because the model will stop when there \n",
    "# is no more better performance in the metrics\n",
    "model0a.fit(x_train, y_train,  epochs = 100, validation_data=(x_train__val, y_train__val), \n",
    "            callbacks=[save_best_checkpoint, stop_early_checkpoint], \n",
    "            verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:34.184262Z",
     "start_time": "2020-06-01T04:34:34.180787Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:34.193324Z",
     "start_time": "2020-06-01T04:34:34.187077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./logs/r_20200601_123434\n"
     ]
    }
   ],
   "source": [
    "def get_run_logdir(root_logdir):\n",
    "    import time\n",
    "    run_id = time.strftime(\"r_%Y%m%d_%H%M%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "root_logdirp = os.path.join(os.curdir, \"logs\")\n",
    "run_logdir = get_run_logdir(root_logdirp)\n",
    "print(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:39.093329Z",
     "start_time": "2020-06-01T04:34:34.195950Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x134418358>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Tensorboard callback and use it\n",
    "tensorboard_cb = tf_keras.callbacks.TensorBoard(run_logdir)\n",
    "model0a.fit(x_train, y_train,  epochs = 100, validation_data=(x_train__val, y_train__val), \n",
    "            callbacks=[save_best_checkpoint, tensorboard_cb], \n",
    "            verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can access the TensorBoard with `python -m tensorboard.main --logdir=r_20200601_122625/`\n",
    "\n",
    "<img src=\"img3c.png\" width=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Readings:\n",
    "\n",
    "- (1)  https://ai.googleblog.com/2016/06/wide-deep-learning-better-together-with.html\n",
    "- (2)  https://github.com/lutzroeder/Netron"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
