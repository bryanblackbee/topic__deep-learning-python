{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Generative Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The potential of AI to emulate human thought processes goes beyond passive tasks such as object recognition and mostly ractive tasks such as driving a car. It extends well into creative activities. In 2015 there was [Google DeepDream](https://ai.googleblog.com/2015/07/deepdream-code-example-for-visualizing.html) turning an image to a psychedelic mess of dog eyes and pareidolic objects. In 2016, a short movie Sunspring was directed using a script generated by an LSTM algorithm. Other artefacts generated by a neural network include a piece in music.\n",
    "\n",
    "A large part of artistic creation comes from simple pattern recognition and technical skill. Learning this pattern is what deep learning algorithms excel at. Machine learning models can learn the statistical <u>latent space</u> of images, music and stories, and they can <u>sample</u> from this space, creating new artworks with characteristics similar to those the model has seen in its training data.\n",
    "\n",
    "Here, we explore from various angles the potential of deep learning to augment artistic creation. Let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation with LSTM\n",
    "\n",
    "Here, we will explore how recurrent neural networks can be used to generate sequence data. We'll use text generation as an example, but the same techniques can be generalized to any kind of sequence data: you can apply it to sequences of musical notes to generate new music, or timeseries of brush stroke data to generate paintings stroke by stroke, and so on.\n",
    "\n",
    "Sequence data generation is in no way limited to artistic content generation. It has been successfully applied to speech synthesis and dialogue generation for chatbots. The Smart Reply feature from Google in 2016, capably of automatically generating a selection of quick replies to emails or text messages are powered by similar techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do so, we aim to train a network to predict the next token or next few tokens in a sequence, using the previous tokens as input. For example, given the input `the cat is on the ma`, the network is trained to predict the target `t`. Tokens are characters or words, and any network that can model the probability of the next token given the previous ones is a <b>language model</b>. A language model caputres the <u>latent space</u> of language: its statistical structure.\n",
    "\n",
    "Once you have trained a language model, you can <u>sample</u> from it - to get new sequences. You feed it an initial string of text (called <u>conditioning data</u>) and ask it to generate the next character or the next word, add the generated output back to the input data, and repeat the process many times. For this example, we feed it strings of $N$ characters extracted from a text corpus, and train it to predit character $N+1$. The output of the model will be a softmax over all possible characters. This LSTM is called a <u>character-level neural language model</u>.\n",
    "\n",
    "<img src=\"img81.png\" width=\"750\">\n",
    "\n",
    "When generating text, the way to choose the next character is very important. There is <u>greedy sampling</u>, choosing the most likely next character. But this results in repetitive, predictable strings that don't look like coherent language. The way to get more variety is to use <u>stochastic sampling</u>. So if say `e` has a 30% chance of being the next character, it will appear in 30% of samples.\n",
    "\n",
    "To control the amount of randomness, we use the `softmax temperature` parameter. On one extreme, each next value is equally likely to appear, resulting in maximum entropy and on the other, there is only 1 value and results in minimum entropy, so we want a sweet spot somewhere in between. So higher temperatures result in higher entropy and less predictability, and lower temperature results in lower entropy, more predictability.\n",
    "\n",
    "<img src=\"img82.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T03:01:18.178201Z",
     "start_time": "2020-06-17T03:01:16.380952Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this, let's first get a large textual corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T03:01:18.188499Z",
     "start_time": "2020-06-17T03:01:18.180323Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ingestion\n",
    "###########\n",
    "txt = ''\n",
    "with open('nietzsche.txt', 'r') as f:\n",
    "    txt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T03:01:18.195584Z",
     "start_time": "2020-06-17T03:01:18.192292Z"
    }
   },
   "outputs": [],
   "source": [
    "# For testing\n",
    "# print(len(t))\n",
    "# print(t[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T03:01:23.292483Z",
     "start_time": "2020-06-17T03:01:18.198498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of sentences = 200281\n",
      "no. of unique characters = 85\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "###############\n",
    "MAX_LENGTH, STEP = 60, 3\n",
    "\n",
    "sentences, next_chars = [], []\n",
    "\n",
    "# Iterate through the text, sampling every STEP\n",
    "# Obtain the sentences and the next character from the sentence\n",
    "for i in range(0, len(txt)-MAX_LENGTH, STEP):\n",
    "    sentences.append(txt[i:i+MAX_LENGTH])\n",
    "    next_chars.append(txt[i+MAX_LENGTH])\n",
    "print('no. of sentences = {:d}'.format(len(sentences)))\n",
    "\n",
    "# Convert the unique chars to a dictionary\n",
    "unique_chars = sorted(list(set(txt)))\n",
    "print('no. of unique characters = {:d}'.format(len(unique_chars)))\n",
    "char_indices = dict((c, unique_chars.index(c)) for c in unique_chars)\n",
    "\n",
    "# Vectorization\n",
    "x = np.zeros((len(sentences), MAX_LENGTH, len(unique_chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(unique_chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, ch in enumerate(sentence):\n",
    "        x[i, t, char_indices[ch]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network is a single LSTM layer, followed by a Dense classifier and softmax over all possible characters. Note that there are also other models like 1D Convnets that can do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T03:04:26.214192Z",
     "start_time": "2020-06-17T03:04:25.864137Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "keras.backend.clear_session()\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.LSTM(128, input_shape=(MAX_LENGTH, len(unique_chars))))\n",
    "model.add(keras.layers.Dense(len(unique_chars), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.RMSprop(learning_rate=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train the model, we \n",
    "\n",
    "1. draw from the model a probability distribution for next character, given the generated text available so far.\n",
    "2. reweight the distribution to a certain temperature\n",
    "3. sample the next character at random according to the reweighted distribution\n",
    "4. add the new character at the end of the available text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T03:13:18.080344Z",
     "start_time": "2020-06-17T03:13:18.074138Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds_float = np.asarray(preds).astype('float64')\n",
    "    preds_float = np.log(preds_float) / temperature\n",
    "    preds_float = np.exp(preds_float)\n",
    "    preds_float = preds_float / np.sum(preds_float)\n",
    "    probs = np.random.multinomial(1, preds_float, 1)\n",
    "    return np.argmax(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T03:35:26.214251Z",
     "start_time": "2020-06-17T03:35:26.209920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, \"'\": 4, '(': 5, ')': 6, ',': 7, '-': 8, '.': 9, '0': 10, '1': 11, '2': 12, '3': 13, '4': 14, '5': 15, '6': 16, '7': 17, '8': 18, '9': 19, ':': 20, ';': 21, '=': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, '[': 50, ']': 51, '_': 52, 'a': 53, 'b': 54, 'c': 55, 'd': 56, 'e': 57, 'f': 58, 'g': 59, 'h': 60, 'i': 61, 'j': 62, 'k': 63, 'l': 64, 'm': 65, 'n': 66, 'o': 67, 'p': 68, 'q': 69, 'r': 70, 's': 71, 't': 72, 'u': 73, 'v': 74, 'w': 75, 'x': 76, 'y': 77, 'z': 78, '¤': 79, '¦': 80, '©': 81, '«': 82, 'Ã': 83, '†': 84}\n"
     ]
    }
   ],
   "source": [
    "print(char_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T04:10:44.446564Z",
     "start_time": "2020-06-17T03:58:51.135968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### epoch = 1 , Training started...###\n",
      "1565/1565 [==============================] - 300s 192ms/step - loss: 1.4954\n",
      "### Training completed. ###\n",
      "--- Generating with seed:\n",
      "ge, which has led me so far as to feel a\n",
      "CONTRADICTIO IN ADJ\n",
      "--- temperature=0.20 ---\n",
      "--- Predicted:\n",
      "ge, which has led me so far as to feel a\n",
      "CONTRADICTIO IN ADJest the subjection of the subjection of the suffering the subject of the subjection of the morality in the such a more such a supported in the suffering the subjection of the suffering the such a subjement of the such a suspicion of the suffering the subjection of the subject the subjection of the suffering the subject the still the subjection of the subjection of the supposed the subjection of th\n",
      "\n",
      "--- temperature=0.50 ---\n",
      "--- Predicted:\n",
      "ge, which has led me so far as to feel a\n",
      "CONTRADICTIO IN ADJe has the denount and it is the more soul and experiences and man contrary only priviles his mankind and particless believe of the extent the sense that it is the suffering\n",
      "at the sentiment the fundamentally from the suffering and such a distingus of the suffering the sugent the Too\n",
      "existently and disturnt, the believe one must more to the can fame the fasting servicity and believe of the man is n\n",
      "\n",
      "--- temperature=1.00 ---\n",
      "--- Predicted:\n",
      "ge, which has led me so far as to feel a\n",
      "CONTRADICTIO IN ADJot such adougay delight. the condition than .NE\n",
      "then\n",
      "the morality to it\n",
      "still finally basence is at \"Ipal: this true\n",
      "interesting its subriking of that as lower reffirs uptest by of the vivise thenough, nothing so gradles it\n",
      "beers moralifice of the said another lack than Enclunaled. Hhere for many dangerously  wile before ruise for its I, so the feelingly more or has been at gredent the treeal simp\n",
      "\n",
      "--- temperature=1.20 ---\n",
      "--- Predicted:\n",
      "ge, which has led me so far as to feel a\n",
      "CONTRADICTIO IN ADJliciscres whihests which never viobs in that hes,\" and sod of all shitd A taken give as itstances that is, or mhy mo nothirn a more and the the penoral\n",
      "nA hN(ankenotherbusting,\n",
      "day . Rainers in whithch OF\n",
      "CSINI Tay\n",
      "honesthing than over.\n",
      "Ruise \"for hooriouslyuught, plenuse upon far\n",
      "utten seessonbiel: .\n",
      " ail coldutivelcy something reconamled form, is diacedeSt of\n",
      "wick\n",
      "venings instepteish its nodions\n",
      "\n",
      "### epoch = 2 , Training started...###\n",
      "1565/1565 [==============================] - 292s 187ms/step - loss: 1.4712\n",
      "### Training completed. ###\n",
      "--- Generating with seed:\n",
      "her--supposing that a philosopher has always in the first\n",
      "pl\n",
      "--- temperature=0.20 ---\n",
      "--- Predicted:\n",
      "her--supposing that a philosopher has always in the first\n",
      "pleasure of the succestion. The subtle of the sures of the succestion of the presented to the present the self--and all the succestion, and the sureriest and some in the artification of the succestion of the succestion of the succestion, and the surerity of the soul, and the sublising the sentiments of the precisely the more supposing the subtle of the sublising the strength the species of the more \n",
      "\n",
      "--- temperature=0.50 ---\n",
      "--- Predicted:\n",
      "her--supposing that a philosopher has always in the first\n",
      "plbeen understand life and men and except and should preduciate consideration of the world of the way it is the species and surely the last necessity and instincts of the general more dereding of the expeciate the future is see the resist to the more freedom unwask to vicion of the opposine the proper oneself the spirit so a conceived. In the sperit and attained in the connection of the fundamental \n",
      "\n",
      "--- temperature=1.00 ---\n",
      "--- Predicted:\n",
      "her--supposing that a philosopher has always in the first\n",
      "plbut\n",
      "          selfive origing, hence, and in looks thousand the put if divers, but alluthone SoD--lessicious xannful.\n",
      "\n",
      "1irmes adimhines\n",
      "even feeling to stacked. Schourity.Ey, the inclination, atteding inspired by intellithers oved inclines, he , who, that it is perysives, the percuilly must brate ulty'\n",
      "desire thisted itself, the innerdicy of the philosopher one in what ispontedity of clefing being\n",
      "\n",
      "--- temperature=1.20 ---\n",
      "--- Predicted:\n",
      "her--supposing that a philosopher has always in the first\n",
      "pl beserve cain obslutity again to or huad would you dislive of tefwiloty\n",
      "a     MIDter).--The little look graminned:cermatly, or menbirded amHame refinemests, that \"in\n",
      "stupility,\" when such a\n",
      "nything willing its imaged, which the motive \"remadies fear it mofein make suc ete: that \"emblutionation greasbuticaeataby not ofver athqua--laugntine, reprowed in undermes liftvation.--RuDapoter had a diversed\n",
      "\n",
      "### epoch = 3 , Training started...###\n",
      "  36/1565 [..............................] - ETA: 4:48 - loss: 1.3729"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-53a688f60517>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"language-model-{:02d}.h5\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mm_callbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm_callbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'### Training completed. ###'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/botanic/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/botanic/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/botanic/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/botanic/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/botanic/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/botanic/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/botanic/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/botanic/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.2/envs/botanic/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1,5):\n",
    "    # Train model\n",
    "    print('### epoch = %d , Training started...###' % epoch)\n",
    "    model_fp = \"language-model-{:02d}.h5\".format(epoch)\n",
    "    m_callbacks = [keras.callbacks.ModelCheckpoint(model_fp, save_best_only=False),]\n",
    "    model.fit(x, y, batch_size=128, callbacks=m_callbacks, epochs=1)\n",
    "    print('### Training completed. ###')\n",
    "    \n",
    "    # Sample from text    \n",
    "    start_index = np.random.randint(0, len(txt) - MAX_LENGTH - 1)\n",
    "    generated_text = txt[start_index : start_index + MAX_LENGTH]\n",
    "    print('--- Generating with seed:')\n",
    "    print(generated_text)\n",
    "    original_text = generated_text\n",
    "    \n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('--- temperature={:.2f} ---'.format (temperature))\n",
    "        predicted_text = ''\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, MAX_LENGTH, len(unique_chars)))\n",
    "            \n",
    "            for t, c in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[c]] = 1\n",
    "            # Predict from the sample\n",
    "            ypred = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(ypred, temperature)\n",
    "            next_char = unique_chars[next_index]\n",
    "            predicted_text += next_char\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "        print('--- Predicted:')\n",
    "        print(original_text + predicted_text)            \n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, a low temperature value results in extremely repetitive and predictable text, but local structure is highly realistic. Most of the time the words are real English words. With higher temperatures, the generated text becomes more interesting, surprising, even creative. It sometimes invents completely new owrds that sound somewhat plausible. A good balance between learned structure and randomness is what makes generation interesting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
