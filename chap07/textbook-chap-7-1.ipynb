{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Advanced Deep Learning Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Keras Functional API\n",
    "\n",
    "So far, the neural networks have been implemented using the `Sequential` model. This assumes that the model has <u>one and only one input</u> and <u>one and only one output</u>. Also, there is a linear stack of layers. Think of it as only 1 path with multiple layers.\n",
    "\n",
    "This is not ideal for some cases. Some networks have multiple independent inputs and some produce multiple outputs. Futhermore, some models have internal branching between layers that make them look like graphs rather than linear stacks of layers.\n",
    "\n",
    "Some tasks require <b>multimodal</b> inputs, that merge data from different input sources, processing each type of data using different kinds of neural layers. It's more ideal to predict jointly using different types of inputs (e.g. images & text) than learning different models for each output. Similarly, some models product multiple target attributes of input data. For example, jointly predicting the year of release and genre of a piece of writing.\n",
    "\n",
    "<img src=\"img71.png\" width=\"600\">\n",
    "<img src=\"img72.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are 3 examples of recent architectures that also don't obey the 1-input, 1-output, 1-stack architecture:\n",
    "\n",
    "- <b>Wide & Deep</b> neural network - This architecture connects all or part of the inputs directly to the output layer. With this architecture, it is possible to learn both deep patterns  (using the deep path) and simple rules (using the short path). More at [Wide & Deep Learning: Better Together with TensorFlow](https://ai.googleblog.com/2016/06/wide-deep-learning-better-together-with.html)\n",
    "<img src=\"img3.png\" width=\"900\"/>\n",
    "\n",
    "- <b>Inception Family</b> - relies on inception modules, where the input is processed by several parallel convolutional branches, and their outputs are merged to a single tensor. More at [Going Deeper with Convolutions](https://arxiv.org/abs/1409.4842)\n",
    "\n",
    "- <b>Adding Residual Connections</b> - A residual connection of injecting previous representations into the downstream flow by adding a past output tensor to a later output tensor. More at [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n",
    "\n",
    "<img src=\"img73.png\" width=\"450\"/>\n",
    "\n",
    "To handle these use cases, and other cases, we cannot use the `Sequential` model but there is a more flexible way to use Keras - the <b>functional model</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:14:38.249162Z",
     "start_time": "2020-06-14T15:14:34.113112Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import boston_housing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Input, layers, models, backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T14:04:06.440383Z",
     "start_time": "2020-06-14T14:04:06.424034Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ingestion\n",
    "###########\n",
    "(train_data, y_train), (test_data, y_test) = boston_housing.load_data()\n",
    "\n",
    "# Preprocessing\n",
    "###############\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(train_data)\n",
    "x_test = sc.transform(test_data)\n",
    "\n",
    "x_train__train, x_train__val, y_train__train, y_train__val = train_test_split(x_train, y_train, test_size=0.15,\n",
    "                                                                             random_state=0)\n",
    "NUM_FEATURES = x_train.shape[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to the Functional API\n",
    "\n",
    "In the functional API, you directly manipulate tensors, and use layers as <u>functions</u> that take tensors and return tensors (hence, functional).\n",
    "\n",
    "#### Single Input, Single Output, One Linear Stack\n",
    "\n",
    "Let's build a side-by-side comparison of a simple model to tackle the **housing prices** regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T14:05:19.435914Z",
     "start_time": "2020-06-14T14:05:16.753250Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using models.Sequential()\n",
    "###########################\n",
    "backend.clear_session()\n",
    "m11 = models.Sequential() # Model\n",
    "m11.add(layers.Dense(32, activation='relu', \n",
    "                     input_shape=(NUM_FEATURES)))\n",
    "m11.add(layers.Dense(32, activation='relu'))\n",
    "m11.add(layers.Dense(1))\n",
    "print(m11.summary())\n",
    "\n",
    "m11.compile(optimizer='rmsprop', loss='mse', metrics=['mae']) # Compile & Fit\n",
    "m11.fit(x_train__train, y_train__train, \n",
    "        epochs=20, batch_size=4,\n",
    "        validation_data= (x_train__val, y_train__val),\n",
    "       verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T14:05:22.420673Z",
     "start_time": "2020-06-14T14:05:19.438886Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using Functional API\n",
    "######################\n",
    "backend.clear_session()\n",
    "m12_input = Input(shape=NUM_FEATURES) # Model\n",
    "m12_l1 = layers.Dense(32, activation='relu')(m12_input)\n",
    "m12_l2 = layers.Dense(32, activation='relu')(m12_l1)\n",
    "m12_output = layers.Dense(1)(m12_l2)\n",
    "m12 = models.Model(m12_input, m12_output)\n",
    "print(m12.summary())\n",
    "m12.compile(optimizer='rmsprop', loss='mse', metrics=['mae']) # Compile & Fit\n",
    "m12.fit(x_train__train, y_train__train, \n",
    "       epochs=20, batch_size=4,\n",
    "       validation_data=(x_train__val, y_train__val),\n",
    "       verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T14:05:22.553668Z",
     "start_time": "2020-06-14T14:05:22.423210Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict step\n",
    "print(m11.predict(x_train__val[:3]))\n",
    "print(m12.predict(x_train__val[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the backend, Keras retrieves every layer going from the inputs to the outputs to a graphs-like data structure, a `Model`. Of course, you need to ensure that there are intermediate layers between the inputs and outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-13T16:14:01.683382Z",
     "start_time": "2020-06-13T16:14:01.678891Z"
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "#### Multiple Inputs, Single Output\n",
    "Now, we shall build a model that have multiple inputs. Typically, for these models, there is a step to merge the different input branches that can combine several tensors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Example 1</b> - The **housing prices problem** now requires we use a subset of the features for one input and another subset of features for another. To do this, we need to make changes on <u>both the architecture</u> and the <u>input data</u>.\n",
    "\n",
    "For the architecture, the key features are:\n",
    "- 2 input layers\n",
    "- concatenate layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T14:04:11.913226Z",
     "start_time": "2020-06-14T14:04:11.843158Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate Model\n",
    "###################\n",
    "# Inputs\n",
    "input_layera = layers.Input(shape=(10,))\n",
    "input_layerb = layers.Input(shape=(7,))\n",
    "\n",
    "# Dense layers, Concatenate layer & Output layer is the same as previous complex workflows\n",
    "hidden_layer1 = layers.Dense(30, activation='relu')(input_layerb)\n",
    "hidden_layer2 = layers.Dense(30, activation='relu')(hidden_layer1)\n",
    "concat_layer = layers.Concatenate()([input_layera, hidden_layer2])\n",
    "output_layer = layers.Dense(1)(concat_layer)\n",
    "m21 = models.Model(inputs=[input_layera, input_layerb], outputs=output_layer)\n",
    "print(m21.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the input data, the key features are:\n",
    "\n",
    "- split the data to different subsets of features\n",
    "- in the `fit()` step, specify the inputs as a list of the 2 inputs, where the order is reflected in the functional API architecture. This needs to be the same in the `.evaluate()` and `predict()` step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T14:04:11.922174Z",
     "start_time": "2020-06-14T14:04:11.915921Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare data for training model\n",
    "#################################\n",
    "inputa_cols = list(range(0,10))\n",
    "inputb_cols = [1,5,6,7,8,11,12]\n",
    "x_train__trainA = x_train__train[:,inputa_cols]\n",
    "x_train__trainB = x_train__train[:,inputb_cols]\n",
    "x_train__val_A = x_train__val[:,inputa_cols]\n",
    "x_train__val_B = x_train__val[:,inputb_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T14:04:11.928546Z",
     "start_time": "2020-06-14T14:04:11.925717Z"
    }
   },
   "outputs": [],
   "source": [
    "# For testing\n",
    "# print(x_train__trainA.shape)\n",
    "# print(x_train__trainB.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T14:04:13.866760Z",
     "start_time": "2020-06-14T14:04:12.493566Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train & Tune Model\n",
    "####################\n",
    "m21.compile(optimizer='sgd', loss='mean_squared_error', metrics=['mae'])\n",
    "m21.fit((x_train__trainA, x_train__trainB), y_train__train, epochs=20,\n",
    "           validation_data=((x_train__val_A, x_train__val_B), y_train__val), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T14:04:22.759811Z",
     "start_time": "2020-06-14T14:04:22.534797Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare test data\n",
    "###################\n",
    "x_testA = x_test[:,inputa_cols]\n",
    "x_testB = x_test[:,inputb_cols]\n",
    "\n",
    "# Evaluation\n",
    "m21.evaluate((x_testA, x_testB), y_test)\n",
    "\n",
    "# Prediction\n",
    "m21.predict((x_testA[:2], x_testB[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Example 2</b> - Consider a **Q&A problem** where there is a reference text and a question as the inputs, and the output is a one-word answer. Conceretely, there is a news article and \"country/person/incident\" as the question, and the outputs is a one-word answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T14:06:27.849626Z",
     "start_time": "2020-06-14T14:06:27.839502Z"
    }
   },
   "outputs": [],
   "source": [
    "TEXT_VOCAB_SIZE, QUESTION_VOCAB_SIZE, ANSWER_VOCAB_SIZE = 10000, 25, 500\n",
    "max_length, max_qn_length, max_ans_length = 100, 25, 5\n",
    "max_samples = 1000\n",
    "\n",
    "text_corpus = np.random.randint(1, TEXT_VOCAB_SIZE,\n",
    "                               size=(max_samples, max_length))\n",
    "questions_corpus = np.random.randint(1, QUESTION_VOCAB_SIZE,\n",
    "                               size=(max_samples, max_qn_length))\n",
    "answers_corpus = np.random.randint(0,ANSWER_VOCAB_SIZE,\n",
    "                                  size=(max_samples,))\n",
    "answers_corpus = to_categorical(answers_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T14:06:27.994517Z",
     "start_time": "2020-06-14T14:06:27.988677Z"
    }
   },
   "outputs": [],
   "source": [
    "print(text_corpus.shape)\n",
    "# print(text_corpus[:2])\n",
    "# print()\n",
    "print(questions_corpus.shape)\n",
    "# print(questions_corpus[:2])\n",
    "# print()\n",
    "print(answers_corpus.shape)\n",
    "# print(answers_corpus[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T14:06:30.213281Z",
     "start_time": "2020-06-14T14:06:29.666648Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "backend.clear_session()\n",
    "m31_corpus_input = Input(shape=(max_length,), dtype='int32')\n",
    "m31_qn_input = Input(shape=(max_qn_length,), dtype='int32')\n",
    "\n",
    "m31_corpus_emb = layers.Embedding(TEXT_VOCAB_SIZE, 64)(m31_corpus_input)\n",
    "m31_qn_emb = layers.Embedding(QUESTION_VOCAB_SIZE, 64)(m31_qn_input)\n",
    "\n",
    "m31_corpus_lstm = layers.LSTM(32)(m31_corpus_emb)\n",
    "m31_qn_lstm = layers.LSTM(32)(m31_qn_emb)\n",
    "\n",
    "m31_concat = layers.Concatenate()([m31_corpus_lstm, m31_qn_lstm])\n",
    "m31_ans = layers.Dense(ANSWER_VOCAB_SIZE, activation='softmax')(m31_concat)\n",
    "m31 = models.Model(inputs=[m31_corpus_input, m31_qn_input], outputs=m31_ans)\n",
    "print(m31.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T14:06:31.087988Z",
     "start_time": "2020-06-14T14:06:31.075564Z"
    }
   },
   "outputs": [],
   "source": [
    "m31.compile(optimizer='rmsprop', \n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T14:06:41.842844Z",
     "start_time": "2020-06-14T14:06:31.267970Z"
    }
   },
   "outputs": [],
   "source": [
    "m31.fit([text_corpus, questions_corpus], answers_corpus, \n",
    "        epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T14:08:30.204899Z",
     "start_time": "2020-06-14T14:08:30.154133Z"
    }
   },
   "outputs": [],
   "source": [
    "m31_pred = m31.predict([text_corpus[:2], questions_corpus[:2]])\n",
    "print(np.argmax(m31_pred[0]))\n",
    "print(np.argmax(m31_pred[1]))\n",
    "print(np.argmax(answers_corpus[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "#### Single Input, Multiple Outputs\n",
    "There are some other models that take one input and simultaneously predict different properties of the data.\n",
    "\n",
    "<b>Example 1</b> - Consider a **social media problem** where the network takes in a social media post as the input and predicts 3 outputs: the age, gender and income level of the poster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:31:27.049152Z",
     "start_time": "2020-06-14T15:31:27.033193Z"
    }
   },
   "outputs": [],
   "source": [
    "# Properties\n",
    "TEXT_VOCAB_SIZE = 50000\n",
    "NUM_GENDER_GROUPS, NUM_AGE_GROUPS = 2, 5\n",
    "text_length = 512 \n",
    "num_samples=1000\n",
    "\n",
    "# Prepare data\n",
    "text_corpus = np.random.randint(1, TEXT_VOCAB_SIZE,\n",
    "                               size=(num_samples, text_length))\n",
    "income_outcomes = np.random.random((num_samples,))\n",
    "gender_outcomes = np.random.randint(0, NUM_GENDER_GROUPS,\n",
    "                                   (num_samples,))\n",
    "age_outcomes = np.random.randint(0, NUM_AGE_GROUPS, \n",
    "                                (num_samples,))\n",
    "# IMPORTANT: When you do multiclass classification, you MUST \n",
    "# one-hot encode the results\n",
    "age_outcomes = to_categorical(age_outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:31:27.564050Z",
     "start_time": "2020-06-14T15:31:27.373776Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "backend.clear_session()\n",
    "input_layer = Input(shape=(None,), dtype='int32', name='posts')\n",
    "\n",
    "embed_layer = layers.Embedding(\n",
    "    TEXT_VOCAB_SIZE, 256, input_length=text_length)(input_layer)\n",
    "stacked_layer = layers.Conv1D(16, 8, activation='relu')(embed_layer)\n",
    "stacked_layer = layers.MaxPooling1D(4)(stacked_layer)\n",
    "stacked_layer = layers.Conv1D(32, 8, activation='relu')(stacked_layer)\n",
    "stacked_layer = layers.GlobalMaxPooling1D()(stacked_layer)\n",
    "stacked_layer = layers.Dense(128, activation='relu')(stacked_layer)\n",
    "\n",
    "age_layer = layers.Dense(NUM_AGE_GROUPS, \n",
    "                         activation='softmax',\n",
    "                         name='age')(stacked_layer)\n",
    "income_layer = layers.Dense(1, name='income')(stacked_layer)\n",
    "gender_layer = layers.Dense(1, activation='sigmoid',\n",
    "                            name='gender')(stacked_layer)\n",
    "m41 = models.Model(input_layer, \n",
    "                   [age_layer, \n",
    "                       income_layer, gender_layer])\n",
    "# print(m41.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:34:01.552601Z",
     "start_time": "2020-06-14T15:32:26.814162Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "12/12 [==============================] - 5s 381ms/step - loss: 0.5147 - age_loss: 0.2895 - income_loss: 0.0655 - gender_loss: 0.1598 - age_acc: 1.0000 - income_mae: 0.1918 - gender_acc: 1.0000 - val_loss: 2.5632 - val_age_loss: 1.6878 - val_income_loss: 0.1281 - val_gender_loss: 0.7473 - val_age_acc: 0.1880 - val_income_mae: 0.3013 - val_gender_acc: 0.4920\n",
      "Epoch 2/20\n",
      "12/12 [==============================] - 4s 371ms/step - loss: 0.2984 - age_loss: 0.1132 - income_loss: 0.1143 - gender_loss: 0.0709 - age_acc: 1.0000 - income_mae: 0.2675 - gender_acc: 1.0000 - val_loss: 2.6485 - val_age_loss: 1.7213 - val_income_loss: 0.1534 - val_gender_loss: 0.7737 - val_age_acc: 0.2040 - val_income_mae: 0.3289 - val_gender_acc: 0.4920\n",
      "Epoch 3/20\n",
      "12/12 [==============================] - 4s 360ms/step - loss: 0.2077 - age_loss: 0.0610 - income_loss: 0.1068 - gender_loss: 0.0399 - age_acc: 1.0000 - income_mae: 0.2694 - gender_acc: 1.0000 - val_loss: 2.7219 - val_age_loss: 1.7540 - val_income_loss: 0.1652 - val_gender_loss: 0.8028 - val_age_acc: 0.1760 - val_income_mae: 0.3413 - val_gender_acc: 0.4920\n",
      "Epoch 4/20\n",
      "12/12 [==============================] - 4s 341ms/step - loss: 0.1318 - age_loss: 0.0361 - income_loss: 0.0704 - gender_loss: 0.0253 - age_acc: 1.0000 - income_mae: 0.2164 - gender_acc: 1.0000 - val_loss: 2.7579 - val_age_loss: 1.7778 - val_income_loss: 0.1359 - val_gender_loss: 0.8442 - val_age_acc: 0.2000 - val_income_mae: 0.3100 - val_gender_acc: 0.4920\n",
      "Epoch 5/20\n",
      "12/12 [==============================] - 4s 338ms/step - loss: 0.1034 - age_loss: 0.0223 - income_loss: 0.0652 - gender_loss: 0.0159 - age_acc: 1.0000 - income_mae: 0.2086 - gender_acc: 1.0000 - val_loss: 2.8352 - val_age_loss: 1.7906 - val_income_loss: 0.1950 - val_gender_loss: 0.8497 - val_age_acc: 0.2000 - val_income_mae: 0.3711 - val_gender_acc: 0.4920\n",
      "Epoch 6/20\n",
      "12/12 [==============================] - 4s 343ms/step - loss: 0.1034 - age_loss: 0.0147 - income_loss: 0.0775 - gender_loss: 0.0112 - age_acc: 1.0000 - income_mae: 0.2295 - gender_acc: 1.0000 - val_loss: 2.8583 - val_age_loss: 1.8062 - val_income_loss: 0.1923 - val_gender_loss: 0.8598 - val_age_acc: 0.2160 - val_income_mae: 0.3681 - val_gender_acc: 0.4920\n",
      "Epoch 7/20\n",
      "12/12 [==============================] - 4s 339ms/step - loss: 0.0770 - age_loss: 0.0109 - income_loss: 0.0576 - gender_loss: 0.0085 - age_acc: 1.0000 - income_mae: 0.1901 - gender_acc: 1.0000 - val_loss: 3.0238 - val_age_loss: 1.8187 - val_income_loss: 0.3213 - val_gender_loss: 0.8838 - val_age_acc: 0.2160 - val_income_mae: 0.4888 - val_gender_acc: 0.4920\n",
      "Epoch 8/20\n",
      "12/12 [==============================] - 4s 338ms/step - loss: 0.0584 - age_loss: 0.0082 - income_loss: 0.0435 - gender_loss: 0.0067 - age_acc: 1.0000 - income_mae: 0.1674 - gender_acc: 1.0000 - val_loss: 3.0147 - val_age_loss: 1.8290 - val_income_loss: 0.2912 - val_gender_loss: 0.8944 - val_age_acc: 0.2040 - val_income_mae: 0.4602 - val_gender_acc: 0.4920\n",
      "Epoch 9/20\n",
      "12/12 [==============================] - 4s 343ms/step - loss: 0.0733 - age_loss: 0.0067 - income_loss: 0.0615 - gender_loss: 0.0051 - age_acc: 1.0000 - income_mae: 0.2025 - gender_acc: 1.0000 - val_loss: 2.9717 - val_age_loss: 1.8344 - val_income_loss: 0.2468 - val_gender_loss: 0.8904 - val_age_acc: 0.2200 - val_income_mae: 0.4190 - val_gender_acc: 0.4920\n",
      "Epoch 10/20\n",
      "12/12 [==============================] - 4s 335ms/step - loss: 0.0708 - age_loss: 0.0054 - income_loss: 0.0611 - gender_loss: 0.0043 - age_acc: 1.0000 - income_mae: 0.2024 - gender_acc: 1.0000 - val_loss: 3.0259 - val_age_loss: 1.8552 - val_income_loss: 0.2273 - val_gender_loss: 0.9434 - val_age_acc: 0.2320 - val_income_mae: 0.4009 - val_gender_acc: 0.4920\n",
      "Epoch 11/20\n",
      "12/12 [==============================] - 4s 341ms/step - loss: 0.0522 - age_loss: 0.0044 - income_loss: 0.0441 - gender_loss: 0.0036 - age_acc: 1.0000 - income_mae: 0.1672 - gender_acc: 1.0000 - val_loss: 3.0921 - val_age_loss: 1.8588 - val_income_loss: 0.3361 - val_gender_loss: 0.8972 - val_age_acc: 0.2080 - val_income_mae: 0.5024 - val_gender_acc: 0.4920\n",
      "Epoch 12/20\n",
      "12/12 [==============================] - 4s 359ms/step - loss: 0.0485 - age_loss: 0.0038 - income_loss: 0.0417 - gender_loss: 0.0030 - age_acc: 1.0000 - income_mae: 0.1629 - gender_acc: 1.0000 - val_loss: 3.0827 - val_age_loss: 1.8684 - val_income_loss: 0.3057 - val_gender_loss: 0.9087 - val_age_acc: 0.2080 - val_income_mae: 0.4737 - val_gender_acc: 0.4920\n",
      "Epoch 13/20\n",
      "12/12 [==============================] - 4s 349ms/step - loss: 0.0499 - age_loss: 0.0034 - income_loss: 0.0437 - gender_loss: 0.0027 - age_acc: 1.0000 - income_mae: 0.1728 - gender_acc: 1.0000 - val_loss: 3.0846 - val_age_loss: 1.8844 - val_income_loss: 0.2742 - val_gender_loss: 0.9259 - val_age_acc: 0.2040 - val_income_mae: 0.4445 - val_gender_acc: 0.4920\n",
      "Epoch 14/20\n",
      "12/12 [==============================] - 4s 355ms/step - loss: 0.0449 - age_loss: 0.0029 - income_loss: 0.0396 - gender_loss: 0.0024 - age_acc: 1.0000 - income_mae: 0.1602 - gender_acc: 1.0000 - val_loss: 3.0655 - val_age_loss: 1.9047 - val_income_loss: 0.1848 - val_gender_loss: 0.9760 - val_age_acc: 0.2040 - val_income_mae: 0.3606 - val_gender_acc: 0.4920\n",
      "Epoch 15/20\n",
      "12/12 [==============================] - 4s 353ms/step - loss: 0.0262 - age_loss: 0.0024 - income_loss: 0.0218 - gender_loss: 0.0020 - age_acc: 1.0000 - income_mae: 0.1170 - gender_acc: 1.0000 - val_loss: 3.1933 - val_age_loss: 1.8824 - val_income_loss: 0.3273 - val_gender_loss: 0.9836 - val_age_acc: 0.1920 - val_income_mae: 0.4942 - val_gender_acc: 0.4920\n",
      "Epoch 16/20\n",
      "12/12 [==============================] - 5s 384ms/step - loss: 0.0368 - age_loss: 0.0020 - income_loss: 0.0331 - gender_loss: 0.0017 - age_acc: 1.0000 - income_mae: 0.1449 - gender_acc: 1.0000 - val_loss: 3.0940 - val_age_loss: 1.9134 - val_income_loss: 0.2289 - val_gender_loss: 0.9518 - val_age_acc: 0.2040 - val_income_mae: 0.4023 - val_gender_acc: 0.4920\n",
      "Epoch 17/20\n",
      "12/12 [==============================] - 4s 343ms/step - loss: 0.0447 - age_loss: 0.0020 - income_loss: 0.0411 - gender_loss: 0.0016 - age_acc: 1.0000 - income_mae: 0.1636 - gender_acc: 1.0000 - val_loss: 3.0723 - val_age_loss: 1.9246 - val_income_loss: 0.2014 - val_gender_loss: 0.9464 - val_age_acc: 0.2120 - val_income_mae: 0.3765 - val_gender_acc: 0.4920\n",
      "Epoch 18/20\n",
      "12/12 [==============================] - 4s 364ms/step - loss: 0.0332 - age_loss: 0.0019 - income_loss: 0.0296 - gender_loss: 0.0017 - age_acc: 1.0000 - income_mae: 0.1404 - gender_acc: 1.0000 - val_loss: 3.0638 - val_age_loss: 1.9148 - val_income_loss: 0.1910 - val_gender_loss: 0.9581 - val_age_acc: 0.2160 - val_income_mae: 0.3665 - val_gender_acc: 0.4920\n",
      "Epoch 19/20\n",
      "12/12 [==============================] - 5s 376ms/step - loss: 0.0306 - age_loss: 0.0016 - income_loss: 0.0278 - gender_loss: 0.0012 - age_acc: 1.0000 - income_mae: 0.1330 - gender_acc: 1.0000 - val_loss: 3.0469 - val_age_loss: 1.9636 - val_income_loss: 0.1681 - val_gender_loss: 0.9151 - val_age_acc: 0.2080 - val_income_mae: 0.3444 - val_gender_acc: 0.4920\n",
      "Epoch 20/20\n",
      "12/12 [==============================] - 4s 358ms/step - loss: 0.0282 - age_loss: 0.0015 - income_loss: 0.0255 - gender_loss: 0.0012 - age_acc: 1.0000 - income_mae: 0.1283 - gender_acc: 1.0000 - val_loss: 3.0316 - val_age_loss: 1.9473 - val_income_loss: 0.2225 - val_gender_loss: 0.8618 - val_age_acc: 0.1720 - val_income_mae: 0.3966 - val_gender_acc: 0.4920\n"
     ]
    }
   ],
   "source": [
    "m41.compile(optimizer='rmsprop', \n",
    "            loss={'age' : 'categorical_crossentropy', \n",
    "                  'income' : 'mse', \n",
    "                  'gender' : 'binary_crossentropy'},\n",
    "            metrics={'age' : 'acc', \n",
    "                     'income' : 'mae', \n",
    "                     'gender' : 'acc'})\n",
    "h41 = m41.fit(text_corpus, \n",
    "        {'age': age_outcomes, \n",
    "         'income' : income_outcomes, \n",
    "         'gender' : gender_outcomes},\n",
    "        epochs=20, batch_size=64, validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T15:34:32.422636Z",
     "start_time": "2020-06-14T15:34:32.389973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>age_loss</th>\n",
       "      <th>income_loss</th>\n",
       "      <th>gender_loss</th>\n",
       "      <th>age_acc</th>\n",
       "      <th>income_mae</th>\n",
       "      <th>gender_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_age_loss</th>\n",
       "      <th>val_income_loss</th>\n",
       "      <th>val_gender_loss</th>\n",
       "      <th>val_age_acc</th>\n",
       "      <th>val_income_mae</th>\n",
       "      <th>val_gender_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.036835</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.033107</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.144874</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.094037</td>\n",
       "      <td>1.913367</td>\n",
       "      <td>0.228900</td>\n",
       "      <td>0.951769</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.402290</td>\n",
       "      <td>0.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.044678</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.041126</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.163551</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.072343</td>\n",
       "      <td>1.924612</td>\n",
       "      <td>0.201363</td>\n",
       "      <td>0.946367</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.376508</td>\n",
       "      <td>0.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.033193</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.029634</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.140448</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.063819</td>\n",
       "      <td>1.914781</td>\n",
       "      <td>0.190971</td>\n",
       "      <td>0.958067</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.366486</td>\n",
       "      <td>0.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.030628</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.027820</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.132962</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.046853</td>\n",
       "      <td>1.963621</td>\n",
       "      <td>0.168141</td>\n",
       "      <td>0.915091</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.344419</td>\n",
       "      <td>0.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.028199</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.025508</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.128252</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.031599</td>\n",
       "      <td>1.947253</td>\n",
       "      <td>0.222498</td>\n",
       "      <td>0.861848</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.396601</td>\n",
       "      <td>0.492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  age_loss  income_loss  gender_loss  age_acc  income_mae  \\\n",
       "15  0.036835  0.002021     0.033107     0.001707      1.0    0.144874   \n",
       "16  0.044678  0.001954     0.041126     0.001598      1.0    0.163551   \n",
       "17  0.033193  0.001859     0.029634     0.001700      1.0    0.140448   \n",
       "18  0.030628  0.001592     0.027820     0.001216      1.0    0.132962   \n",
       "19  0.028199  0.001462     0.025508     0.001229      1.0    0.128252   \n",
       "\n",
       "    gender_acc  val_loss  val_age_loss  val_income_loss  val_gender_loss  \\\n",
       "15         1.0  3.094037      1.913367         0.228900         0.951769   \n",
       "16         1.0  3.072343      1.924612         0.201363         0.946367   \n",
       "17         1.0  3.063819      1.914781         0.190971         0.958067   \n",
       "18         1.0  3.046853      1.963621         0.168141         0.915091   \n",
       "19         1.0  3.031599      1.947253         0.222498         0.861848   \n",
       "\n",
       "    val_age_acc  val_income_mae  val_gender_acc  \n",
       "15        0.204        0.402290           0.492  \n",
       "16        0.212        0.376508           0.492  \n",
       "17        0.216        0.366486           0.492  \n",
       "18        0.208        0.344419           0.492  \n",
       "19        0.172        0.396601           0.492  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(h41.history).tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a wide & deep network to tackle the **housing prices** problem. Take note of the comments describing each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:28.830889Z",
     "start_time": "2020-06-01T04:34:28.753361Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate Model\n",
    "###################\n",
    "\n",
    "# Input object. This is needed as we might have multiple inputs.\n",
    "input_layer = tf_keras.layers.Input(shape=NUM_FEATURES)\n",
    "\n",
    "# Dense layer with 30 neurons & RELU activation. Notice it is called like a function,\n",
    "# passing in the input layer. \n",
    "hidden_layer1 = tf_keras.layers.Dense(30, activation='relu')(input_layer)\n",
    "# Another Dense layer. Now, the first hidden layer is passed in.\n",
    "hidden_layer2 = tf_keras.layers.Dense(30, activation='relu')(hidden_layer1)\n",
    "\n",
    "# Concatenate layer. concatenates the input & the output of the 2nd hidden layer\n",
    "concat_layer = tf_keras.layers.Concatenate()([input_layer, hidden_layer2])\n",
    "\n",
    "# Output layer. Single neuron and no activation function.\n",
    "output_layer = tf_keras.layers.Dense(1)(concat_layer)\n",
    "\n",
    "# Finally, create the Keras model with this architecture.\n",
    "model0 = tf_keras.models.Model(inputs=[input_layer], outputs=output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above model is visually represented by the following network diagram:\n",
    "<img src=\"img3a.png\" width=\"150\"/>\n",
    "(Ref. 2)\n",
    "\n",
    "Once you have built the Keras model, the rest of the steps follows the simple workflow: Compile the model, train & tune it, and finalise the tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:29.431274Z",
     "start_time": "2020-06-01T04:34:28.834139Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train & Tune Model\n",
    "####################\n",
    "model0.compile(optimizer='sgd', loss='mean_squared_error', metrics=['mae'])\n",
    "history0 = model0.fit(x_train, y_train,  epochs = 10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:29.436017Z",
     "start_time": "2020-06-01T04:34:29.433288Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "# model0.save('model0.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Multiple inputs, Single output</b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Multiple inputs, Multiple outputs</b>\n",
    "\n",
    "For multiple outputs, you can use the following code snippets to help you.\n",
    "\n",
    "```python\n",
    "input_layera = tf_keras.layers.Input(shape=(10,))\n",
    "input_layerb = tf_keras.layers.Input(shape=(7,))\n",
    "\n",
    "hidden_layer1 = tf_keras.layers.Dense(30, activation='relu')(input_layerb)\n",
    "hidden_layer2 = tf_keras.layers.Dense(30, activation='relu')(hidden_layer1)\n",
    "concat_layer = tf_keras.layers.Concatenate()([input_layera, hidden_layer2])\n",
    "output_layer1 = tf_keras.layers.Dense(1)(concat_layer)\n",
    "output_layer2 = tf_keras.layers.Dense(1)(hidden_layer2) # Add this\n",
    "model3 = tf_keras.models.Model(inputs=[input_layera, input_layerb], \n",
    "                               outputs=[output_layer1, output_layer2]) # Change this\n",
    "```\n",
    "\n",
    "When compiling the model, use different metrics for different outputs\n",
    "\n",
    "```python\n",
    "model3.compile(optimizer='sgd', loss='mean_squared_error', metrics=['mae', 'mse'])\n",
    "```\n",
    "\n",
    "When evaluating the model, Keras returns the total loss, as well as the individual losses\n",
    "```python\n",
    "model3.evaluate((x_testA, x_testB), y_test)```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Dynamic Models Using the Subclassing API\n",
    "\n",
    "To add flexibility, we can use the Subclassing API to subclass the Model and create the layers needed.\n",
    "\n",
    "Here, we separate the creating of the layers from their usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:31.038033Z",
     "start_time": "2020-06-01T04:34:31.030801Z"
    }
   },
   "outputs": [],
   "source": [
    "class WideAndDeepModel(tf_keras.models.Model):\n",
    "    def __init__(self, units=30, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden_layer1 = tf_keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden_layer2 = tf_keras.layers.Dense(units, activation=activation)\n",
    "        self.output_layer = tf_keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        inputa, inputb = inputs\n",
    "        hidden1 = self.hidden_layer1(inputb)\n",
    "        hidden2 = self.hidden_layer2(hidden1)\n",
    "        conct = tf_keras.layers.Concatenate()([inputa, hidden2])\n",
    "        ouptt = self.output_layer(conct)\n",
    "        return ouptt\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:32.456367Z",
     "start_time": "2020-06-01T04:34:31.040944Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load & Train model\n",
    "model3 = WideAndDeepModel(30, 'relu')\n",
    "model3.compile(optimizer='sgd', loss='mean_squared_error', metrics=['mae'])\n",
    "model3.fit((x_train__trainA, x_train__trainB), y_train__train, epochs=20,\n",
    "           validation_data=((x_train__val_A, x_train__val_B), y_train__val), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:32.572023Z",
     "start_time": "2020-06-01T04:34:32.459904Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate & Predict\n",
    "model3.evaluate((x_testA, x_testB), y_test)\n",
    "model3.predict((x_testA[:2], x_testB[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving & Restoring a Model\n",
    "\n",
    "This is useful when models take a long time to train or when you need access to a previously trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:32.594420Z",
     "start_time": "2020-06-01T04:34:32.574316Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving a model\n",
    "model1.save('model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:32.719754Z",
     "start_time": "2020-06-01T04:34:32.596313Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load & Predict\n",
    "model1ld = tf_keras.models.load_model('model3.h5')\n",
    "model1ld.predict((x_testA[10:15], x_testB[10:15]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:17:00.759288Z",
     "start_time": "2020-06-01T04:17:00.754188Z"
    }
   },
   "source": [
    "Callbacks are useful to perform actions during training. For example, say we want to save the best model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:33.591641Z",
     "start_time": "2020-06-01T04:34:32.721914Z"
    }
   },
   "outputs": [],
   "source": [
    "input_layer = tf_keras.layers.Input(shape=NUM_FEATURES)\n",
    "hidden_layer1 = tf_keras.layers.Dense(30, activation='relu')(input_layer)\n",
    "hidden_layer2 = tf_keras.layers.Dense(30, activation='relu')(hidden_layer1)\n",
    "concat_layer = tf_keras.layers.Concatenate()([input_layer, hidden_layer2])\n",
    "output_layer = tf_keras.layers.Dense(1)(concat_layer)\n",
    "model0a = tf_keras.models.Model(inputs=[input_layer], outputs=output_layer)\n",
    "model0a.compile(optimizer='sgd', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Adding a callback to save only the best model\n",
    "save_best_checkpoint = tf_keras.callbacks.ModelCheckpoint('model0a_best.h5', save_best_only=True)\n",
    "model0a.fit(x_train, y_train,  epochs = 10, validation_data=(x_train__val, y_train__val), \n",
    "            callbacks=[save_best_checkpoint], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:34.178491Z",
     "start_time": "2020-06-01T04:34:33.593980Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adding a callback to Early Stop to avoid wasting time and resources\n",
    "# with no further optimisation\n",
    "stop_early_checkpoint = tf_keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "# Combine both callbacks. Use large epoch number because the model will stop when there \n",
    "# is no more better performance in the metrics\n",
    "model0a.fit(x_train, y_train,  epochs = 100, validation_data=(x_train__val, y_train__val), \n",
    "            callbacks=[save_best_checkpoint, stop_early_checkpoint], \n",
    "            verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:34.184262Z",
     "start_time": "2020-06-01T04:34:34.180787Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:34.193324Z",
     "start_time": "2020-06-01T04:34:34.187077Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_run_logdir(root_logdir):\n",
    "    import time\n",
    "    run_id = time.strftime(\"r_%Y%m%d_%H%M%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "root_logdirp = os.path.join(os.curdir, \"logs\")\n",
    "run_logdir = get_run_logdir(root_logdirp)\n",
    "print(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:39.093329Z",
     "start_time": "2020-06-01T04:34:34.195950Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the Tensorboard callback and use it\n",
    "tensorboard_cb = tf_keras.callbacks.TensorBoard(run_logdir)\n",
    "model0a.fit(x_train, y_train,  epochs = 100, validation_data=(x_train__val, y_train__val), \n",
    "            callbacks=[save_best_checkpoint, tensorboard_cb], \n",
    "            verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can access the TensorBoard with `python -m tensorboard.main --logdir=r_20200601_122625/`\n",
    "\n",
    "<img src=\"img3c.png\" width=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Readings:\n",
    "\n",
    "- (1)  https://ai.googleblog.com/2016/06/wide-deep-learning-better-together-with.html\n",
    "- (2)  https://github.com/lutzroeder/Netron"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
