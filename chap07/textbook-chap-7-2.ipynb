{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Advanced Deep Learning Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "\n",
    "When training a model, there are many things you cannot predict from the start. For example you cannot predict the number of epochs needed to get an optimal validation loss. Typically, you train for the specified number of epochs, then select the optimal number of epochs to train for and train again. This approach is wasteful.\n",
    "\n",
    "A much better way to handle this is to stop training when you realise the validation loss is no longer improving. This can be achieved using a Keras callback. A <b>callback</b> is an object that is passed in the model in the call to `fit()` and is called by the model at various points during training. It has access to all the availebl data about the state of the model and can take various actions: interrupt training, save model, load weight sets etc. Some common callbacks are:\n",
    "\n",
    "- `callbacks.ModelCheckpoint`\n",
    "- `callbacks.EarlyStopping`\n",
    "- `callbacks.LearningRateScheduler`\n",
    "- `callbacks.ReduceLROnPlateau`\n",
    "- `callbacks.CSVLogger`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:33.591641Z",
     "start_time": "2020-06-01T04:34:32.721914Z"
    }
   },
   "outputs": [],
   "source": [
    "input_layer = tf_keras.layers.Input(shape=NUM_FEATURES)\n",
    "hidden_layer1 = tf_keras.layers.Dense(30, activation='relu')(input_layer)\n",
    "hidden_layer2 = tf_keras.layers.Dense(30, activation='relu')(hidden_layer1)\n",
    "concat_layer = tf_keras.layers.Concatenate()([input_layer, hidden_layer2])\n",
    "output_layer = tf_keras.layers.Dense(1)(concat_layer)\n",
    "model0a = tf_keras.models.Model(inputs=[input_layer], outputs=output_layer)\n",
    "model0a.compile(optimizer='sgd', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Adding a callback to save only the best model\n",
    "save_best_checkpoint = tf_keras.callbacks.ModelCheckpoint('model0a_best.h5', save_best_only=True)\n",
    "model0a.fit(x_train, y_train,  epochs = 10, validation_data=(x_train__val, y_train__val), \n",
    "            callbacks=[save_best_checkpoint], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:34.178491Z",
     "start_time": "2020-06-01T04:34:33.593980Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adding a callback to Early Stop to avoid wasting time and resources\n",
    "# with no further optimisation\n",
    "stop_early_checkpoint = tf_keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "# Combine both callbacks. Use large epoch number because the model will stop when there \n",
    "# is no more better performance in the metrics\n",
    "model0a.fit(x_train, y_train,  epochs = 100, validation_data=(x_train__val, y_train__val), \n",
    "            callbacks=[save_best_checkpoint, stop_early_checkpoint], \n",
    "            verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:34.184262Z",
     "start_time": "2020-06-01T04:34:34.180787Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:34.193324Z",
     "start_time": "2020-06-01T04:34:34.187077Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_run_logdir(root_logdir):\n",
    "    import time\n",
    "    run_id = time.strftime(\"r_%Y%m%d_%H%M%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "root_logdirp = os.path.join(os.curdir, \"logs\")\n",
    "run_logdir = get_run_logdir(root_logdirp)\n",
    "print(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-01T04:34:39.093329Z",
     "start_time": "2020-06-01T04:34:34.195950Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the Tensorboard callback and use it\n",
    "tensorboard_cb = tf_keras.callbacks.TensorBoard(run_logdir)\n",
    "model0a.fit(x_train, y_train,  epochs = 100, validation_data=(x_train__val, y_train__val), \n",
    "            callbacks=[save_best_checkpoint, tensorboard_cb], \n",
    "            verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can access the TensorBoard with `python -m tensorboard.main --logdir=r_20200601_122625/`\n",
    "\n",
    "<img src=\"img3c.png\" width=\"750\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Readings:\n",
    "\n",
    "- (1)  https://ai.googleblog.com/2016/06/wide-deep-learning-better-together-with.html\n",
    "- (2)  https://github.com/lutzroeder/Netron"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
